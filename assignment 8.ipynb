{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c058810c",
   "metadata": {},
   "source": [
    "Q2\n",
    "link:https://chatgpt.com/share/673cf4a2-e7cc-8009-b8d6-cc6930fb3790\n",
    "\n",
    "1. Accuracy (Overall Correctness):\n",
    "Best for: Balanced, equally consequential scenarios\n",
    "Example: Coin Flip Prediction Machine\n",
    "Rationale:\n",
    "- Equal importance to correct and incorrect classifications\n",
    "- Total proportion of correct decisions matters\n",
    "- Dataset has roughly equal distribution of outcomes\n",
    "- No severe consequences for either type of error\n",
    "\n",
    "2. Sensitivity (Catching Positives):\n",
    "Best for: High-stakes screening with catastrophic negative consequences\n",
    "Example: Cancer Screening Test\n",
    "Rationale:\n",
    "- Missing a positive case is far worse than false alarms\n",
    "- Prioritize identifying every potential serious condition\n",
    "- Follow-up confirmatory tests can manage false positives\n",
    "- Goal is to catch ALL potential cases, minimizing missed diagnoses\n",
    "\n",
    "3. Specificity (Ruling Out Negatives):\n",
    "Best for: Scenarios where false positives create significant disruption\n",
    "Example: Airport Security Screening\n",
    "Rationale:\n",
    "- Unnecessary security interventions are costly and disruptive\n",
    "- Minimizing false alarms is critical\n",
    "- Prefer letting potential threats pass than causing widespread inconvenience\n",
    "- High bar for positive identification needed\n",
    "\n",
    "4. Precision (Trustworthiness of Positive Results):\n",
    "Best for: Resource-intensive investigation processes\n",
    "Example: Fraud Detection in Financial Transactions\n",
    "Rationale:\n",
    "- Each investigated case requires substantial time/resources\n",
    "- Want to minimize wasted efforts on false alarms\n",
    "- Acceptable to miss some instances if detected cases are highly reliable\n",
    "- Focus on ensuring detected cases are truly positive\n",
    "\n",
    "Key Insight: The choice of metric depends on the relative cost of different types of errors in your specific context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7658b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m130\u001b[39m)  \n\u001b[0;32m----> 8\u001b[0m ab_reduced_noNaN_train, ab_reduced_noNaN_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(\n\u001b[1;32m      9\u001b[0m     ab_reduced_noNaN, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m130\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set observations:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ab_reduced_noNaN_train))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting set observations:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ab_reduced_noNaN_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "#link:https://chatgpt.com/share/673cf4a2-e7cc-8009-b8d6-cc6930fb3790\n",
    "\n",
    "#80/20 Split:\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(130)  \n",
    "\n",
    "ab_reduced_noNaN_train, ab_reduced_noNaN_test = train_test_split(\n",
    "    ab_reduced_noNaN, test_size=0.2, random_state=130\n",
    ")\n",
    "\n",
    "print(\"Training set observations:\", len(ab_reduced_noNaN_train))\n",
    "print(\"Testing set observations:\", len(ab_reduced_noNaN_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d982f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mget_dummies(ab_reduced_noNaN[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHard_or_Paper\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m ab_reduced_noNaN[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mList Price\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Prepare Data:\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "X = ab_reduced_noNaN[['List Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classification:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']\n",
    "X_train = ab_reduced_noNaN_train[['List Price']]\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=130)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_tree(clf, feature_names=['List Price'], \n",
    "          class_names=['Paperback', 'Hardcover'], \n",
    "          filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f23fae",
   "metadata": {},
   "source": [
    "Explanation of the Decision Tree:\n",
    "\n",
    "The tree uses only 'List Price' to classify books\n",
    "It creates 2-3 decision nodes based on price thresholds\n",
    "Each leaf node represents the predicted book type (hardcover or paperback)\n",
    "The color intensity indicates the purity of the classification at each node\n",
    "Darker colors suggest more confident predictions\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "The first split is based on a specific List Price threshold\n",
    "Subsequent splits further refine the classification\n",
    "Shows how a simple decision tree uses price to distinguish book types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5873130",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mget_dummies(ab_reduced_noNaN_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHard_or_Paper\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m X_test \u001b[38;5;241m=\u001b[39m ab_reduced_noNaN_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mList Price\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     10\u001b[0m y_pred_clf \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "#link:\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_test = pd.get_dummies(ab_reduced_noNaN_test[\"Hard_or_Paper\"])['H']\n",
    "X_test = ab_reduced_noNaN_test[['List Price']]\n",
    "\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_pred_clf2 = clf2.predict(X_test)\n",
    "\n",
    "cm_clf = confusion_matrix(y_test, y_pred_clf)\n",
    "tn_clf, fp_clf, fn_clf, tp_clf = cm_clf.ravel()\n",
    "\n",
    "cm_clf2 = confusion_matrix(y_test, y_pred_clf2)\n",
    "tn_clf2, fp_clf2, fn_clf2, tp_clf2 = cm_clf2.ravel()\n",
    "\n",
    "sensitivity_clf = np.round(tp_clf / (tp_clf + fn_clf), 3)\n",
    "specificity_clf = np.round(tn_clf / (tn_clf + fp_clf), 3)\n",
    "accuracy_clf = np.round((tp_clf + tn_clf) / (tp_clf + tn_clf + fp_clf + fn_clf), 3)\n",
    "\n",
    "sensitivity_clf2 = np.round(tp_clf2 / (tp_clf2 + fn_clf2), 3)\n",
    "specificity_clf2 = np.round(tn_clf2 / (tn_clf2 + fp_clf2), 3)\n",
    "accuracy_clf2 = np.round((tp_clf2 + tn_clf2) / (tp_clf2 + tn_clf2 + fp_clf2 + fn_clf2), 3)\n",
    "\n",
    "print(\"Model 1 (clf) Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_clf}\")\n",
    "print(f\"Specificity: {specificity_clf}\")\n",
    "print(f\"Accuracy: {accuracy_clf}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_clf)\n",
    "\n",
    "print(\"\\n\\nModel 2 (clf2) Metrics:\")\n",
    "print(f\"Sensitivity: {sensitivity_clf2}\")\n",
    "print(f\"Specificity: {specificity_clf2}\")\n",
    "print(f\"Accuracy: {accuracy_clf2}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607eff27",
   "metadata": {},
   "source": [
    "Key Insights:\n",
    "- Sensitivity: Proportion of actual hardcovers correctly identified\n",
    "- Specificity: Proportion of actual paperbacks correctly identified\n",
    "- Accuracy: Overall proportion of correct classifications\n",
    "\n",
    "Interpretation:\n",
    "- Each model's performance can be compared across these three metrics\n",
    "- Different models might excel in different aspects (sensitivity vs. specificity)\n",
    "- Choose model based on which metric is most critical for your specific use case\n",
    "\n",
    "The confusion matrix shows:\n",
    "- True Positives (TP)\n",
    "- True Negatives (TN)\n",
    "- False Positives (FP)\n",
    "- False Negatives (FN)\n",
    "\n",
    "This allows a comprehensive view of the model's classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaa01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7\n",
    "#link:\n",
    "\n",
    "#In the first confusion matrix, the prediction is made using only the 'List Price' feature:\n",
    "clf.predict(ab_reduced_noNaN_train[['List Price']])\n",
    "\n",
    "#In the first confusion matrix, the prediction is made using only the 'List Price' feature:\n",
    "clf.predict(ab_reduced_noNaN_train[['NumPages','Thick','List Price']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad531556",
   "metadata": {},
   "source": [
    "The additional features in the second confusion matrix (NumPages and Thick) likely provide more information to the model, leading to a different classification performance compared to the first matrix that only used the 'List Price' feature.\n",
    "The two confusion matrices above (for clf and clf2) are better because they provide more detailed information about the model's performance. By including additional features, the second confusion matrix can give insights into how the model is performing on different aspects of the data, rather than just relying on a single feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
